/*
Copyright (C) 2009 Scott Grauer-Gray, Chandra Kambhammettu, and Kannappan Palaniappan
This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
*/


GPU Implementation of Belief Propagation for stereo using CUDA

S. Grauer-Gray, C. Kambhammettu, and K.Palaniappan

This README describes an implementation of the CUDA belief propagation algorithm described in our paper 
"GPU implementation of belief propagation using CUDA for cloud tracking and reconstruction" which was 
published at the 2008 IAPR Workshop on Pattern Recognition in Remote Sensing (PRRS 2008) and can be 
found at the following address: http://scottgg.net/cudaBeliefProp.pdf.  Please cite this 
work if using any of this code as part of a research paper or other work.

Will note that there have been changes from the initial implementation as presented in the paper, both for
optimization, to work on the latest NVIDIA GPUs with the latest CUDA toolkits, and to add a parallel CPU
implementation.  Also, the motion estimation portion of the code was removed to narrow the focus of this
work (though could certainly be added back in the future).  The additional optimizations as well as the
parallel CPU implementation are described in
http://scottgg.net/OptimizingGlobalStereoMatchingOnNVIDIAGPUsAndCPUs.pdf.

The original code is available at http://scottgg.net/beliefPropCodePost.zip.

See "RUNTIME RESULTS USING CURRENT CODE" section at end of README for runtime info across various
processors including the NVIDIA A100 GPU and AMD Rome 48-core/96-thread CPU.

This code is distributed using the GNU General Public License, so any derivative work which 
is distributed must also contain this license.

Please email comments and bug reports to: sgrauerg@gmail.com


USAGE:

This code runs belief propagation for stereo vision on the CPU and GPU using CUDA on Windows and Linux-based systems.

The parameters are defined in ParameterFiles/bpStereoParameters.h and are documented in that file and the paper.  
In order to compile/re-compile the program, navigate to the directory LinuxMakeAndRunBPOptimizedCPU (for optimized GPU
implementation or LinuxMakeAndRunBPCUDA (for CUDA implementation) and run "make clean" and "make".  To run the CUDA
code, the CUDA installation must have a symbolic link to /usr/local/cuda/ for the Makefile to work as is.

A number of stereo sets including the Tsukuba stereo are included in the "StereoSets" folder.  In order to run the
implementation on these stereo sets using the initial parameters as defined in ParameterFiles/bpStereoParameters.h,
perform the following steps:

LINUX:

1a.  (CUDA ONLY) If needed, set the PATH and LD_LIBRARY_PATH to the necessary paths needed to run CUDA programs
(usually PATH is appended with $CUDA_DIR/bin and LD_LIBRARY_PATH=$CUDA_DIR/lib or LD_LIBRARY_PATH=$CUDA_DIR/lib64).

1b. (CPU ONLY) Make any necessary or desired adjustments to run on target CPU:

-If ARM CPU, uncomment the line "//#define COMPILING_FOR_ARM" in ParameterFiles/bpRunSettings.h (line 19).  This will
make the necessary configuration changes to support processing on ARM CPUs.

-If x86 CPU, set vectorization to AVX-256 if AVX-512 is not supported on target CPU in line
"#define CPU_VECTORIZATION_DEFINE {SETTING}" in ParameterFiles/bpRunSettings.h (line 59).

-May also want to adjust environment variables OMP_PLACES and OMP_PROC_BIND to optimize OpenMP thread configuration.
In some tests have gotten faster results with setting OMP_PROC_BIND=true but in other tests have gotten better
results with default configuration and not setting OMP_PROC_BIND.

2.  If running optimized CPU implementation, navigate to the folder LinuxMakeAndRunBPOptimizedCPU.
    If running CUDA implemenetation, navigate to folder LinuxMakeAndRunBPCUDA CUDA implementation Makefile.

3.  Execute the commands "make clean" and "make" on the command line.

4.  Call created "driverCPUBp" or "driverCudaBp" executable to run the implementation on multiple stereo sets
and in multiple configurations. The implementation is run multiple times to more accurately measure the runtime.
The single-thread CPU implementation code from http://cs.brown.edu/people/pfelzens/bp/index.html is also run to
make it possible to compare the output disparity maps/runtimes from the original single-thread implementation with
the optimized implementations.

5.  The locations of the output disparity maps are given in the console output.  More detailed info including input
stereo set and parameters, detailed timings along with overall speedup data, and output disparity map evaluation as
compared to ground truth for each run are written to a outputResultsDefaultParallelParams_MULT_DATA_TYPES_{acceleration_type}.csv
file; this file is in the same folder as the driverCPUBp/driverCudaBp executable.

6.  In order to adjust the parameters to run on different inputs or with different parameters, set the desired
parameters in ParameterFiles/bpStereoParameters.h, run "make clean" and "make" to compile the program with the
adjusted parameters, and then call the executable to run the program with the adjusted parameters.

WINDOWS (MAY NOT CURRENTLY WORK AS IS; HASN'T BEEN TESTED FOR AWHILE):

1. Open CreateBeliefPropDLLs.sln Visual Studio Project in WindowsVSCreateDLLsWithRunBPWithDLLs/CreateBeliefPropDLLs folder.  

2. Select to compile then run the application.  The solution will first compile the single-thread CPU, optimized CPU, 
and CUDA implementations into DLLs, then the main program in the solution will load the DLLs and run the program.  The
program output shows the optimized CPU and CUDA implementation results compared to the single-thread CPU implementation results.

Parameters can be adjusted in the ParameterFiles/bpStereoParameters.h file and will need to re-compile to see results with adjusted parameters.


RUNTIME RESULTS USING CURRENT CODE:

Relative speedup across various processors (previous run using AMD Rome w/ 48 cores used as baseline):
-Column marked as "Total runtime including data transfer time (15 timings)" in outputResults.csv used for runtime comparison.
-Speedup given is average across a number of input stereo sets and configurations.
-CPU and CUDA runs are with thread count / thread block optimization enabled (via OPTIMIZE_PARALLEL_PARAMS in MainDriverFiles/driverCudaBp.cpp / MainDriverFiles/driverBpStereoCPU.cpp set to true)
NVIDIA P100: 0.785x
Amazon Graviton2 (64 core ARM server): 0.925x
AMD Rome (48 cores): 0.97x
Intel Ice Lake (32 cores): 0.975x
NVIDIA V100: 1.14x
Amazon Graviton3 (64 core ARM server): 1.21x
AMD Milan-X (120 cores / 2 sockets...limited to 60 threads with OpenMP threads pinned to socket so should be using single 60 core CPU): 1.35x
NVIDIA RTX 3090 Ti: 1.65x
NVIDIA A100: 1.80x
NVIDIA H100: 2.40x
Spreadsheet with more detailed results:
https://docs.google.com/spreadsheets/d/1pFMbbEGv1ulor1HP0lZNnd1IL8xETfr3tHRk_S9VzzE/edit?usp=sharing