/*
Copyright (C) 2009 Scott Grauer-Gray, Chandra Kambhammettu, and Kannappan Palaniappan
This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
*/


GPU Implementation of Belief Propagation for stereo using CUDA

S. Grauer-Gray, C. Kambhammettu, and K.Palaniappan

This README describes an implementation of the CUDA belief propagation algorithm described in our paper 
"GPU implementation of belief propagation using CUDA for cloud tracking and reconstruction" which was 
published at the 2008 IAPR Workshop on Pattern Recognition in Remote Sensing (PRRS 2008) and can be 
found at the following address: http://scottgg.net/cudaBeliefProp.pdf.  Please cite this 
work if using any of this code as part of a research paper or other work.

Will note that there have been changes from the initial implementation as presented in the paper, both for
optimization, to work on the latest NVIDIA GPUs with the latest CUDA toolkits, and to add a parallel CPU
implementation.  Also, the motion estimation portion of the code was removed to narrow the focus of this
work (though could certainly be added back in the future).  The additional optimizations as well as the
parallel CPU implementation are described in
http://scottgg.net/OptimizingGlobalStereoMatchingOnNVIDIAGPUsAndCPUs.pdf.

The original code is available at http://scottgg.net/beliefPropCodePost.zip.

See "RUNTIME RESULTS USING CURRENT CODE" section at end of README for runtime info across various
processors including the NVIDIA A100 and H100 GPUs, AMD Rome and Milan-X CPUs, and Intel Ice Lake CPU.

This code is distributed using the GNU General Public License, so any derivative work which 
is distributed must also contain this license.

Please email comments and bug reports to: sgrauerg@gmail.com


LINUX USAGE AND INSTRUCTIONS:

This code runs belief propagation for stereo vision on the CPU and GPU using CUDA on Linux-based systems.

The parameters are defined in BpConstsAndParams/bpStereoParameters.h and are documented in that file and the paper.  
In order to compile/re-compile the program, navigate to the directory LinuxMakeAndRunBPOptimizedCPU (for optimized GPU
implementation on x86 processors), the directory LinuxMakeAndRunBPOptimizedCPU (for optimized CPU implementation on ARM
processors), or LinuxMakeAndRunBPCUDA (for CUDA implementation) and run "make clean" and "make".

A number of stereo sets including the Tsukuba stereo are included in the "StereoSets" folder.  In order to run the
implementation on these stereo sets using the initial parameters as defined in BpConstsAndParams/bpStereoParameters.h,
perform the following steps:

1a.  (CUDA ONLY) If needed, set the PATH and LD_LIBRARY_PATH to the necessary paths needed to run CUDA programs
(usually PATH is appended with $CUDA_DIR/bin and LD_LIBRARY_PATH=$CUDA_DIR/lib64).

-If using a CUDA device of Compute Capability 8.0 or higher, can switch half-precision processing from the
default "half" datatype to the bfloat16 datatype by removing the comment in the line 
"BFLOAT_DATA_TYPE_SETTING = #-DUSE_BFLOAT16_FOR_HALF_PRECISION" in LinuxMakeAndRunBPCUDA/Makefile (line 28)...this change
fixes a bug with processing of conesFullSizeCropped at half-precision using CUDA (see "ADDITIONAL NOTE").

1b.  (CPU ONLY) Make any necessary or desired adjustments to run on target CPU:

-On x86 CPU, AVX-512 vectorization is used by default.  If AVX-512 is not supported on target CPU, set vectorization
to AVX-256 by changing line 18 of LinuxMakeAndRunBPOptimizedCPU/Makefile.h from
"CPU_VECTORIZATION_DEFINE = -DAVX_512_VECTORIZATION" (line 18) to "CPU_VECTORIZATION_DEFINE = -DAVX_256_VECTORIZATION".

-May also want to adjust environment variables OMP_PLACES and OMP_PROC_BIND to optimize OpenMP thread configuration.
In some tests have gotten faster results with setting OMP_PROC_BIND=true but in other tests have gotten better
results with default configuration and not setting OMP_PROC_BIND.

2.  If running optimized CPU implementation on x86 CPU, navigate to the folder LinuxMakeAndRunBPOptimizedCPU.
    If running optimized CPU implementation on ARM CPU, navigate to the folder LinuxMakeAndRunBPOptimizedCPU_ARM.
    If running CUDA implemenetation, navigate to folder LinuxMakeAndRunBPCUDA.

3.  Execute the commands "make clean" and "make" on the command line.

4.  Call created "driverCPUBp" or "driverCudaBp" executable to run the implementation on multiple stereo sets
and in multiple configurations.  Implementation is run multiple times to more accurately measure the runtime.
The single-thread CPU implementation code from http://cs.brown.edu/people/pfelzens/bp/index.html is also run to
compare the output disparity maps/runtimes from the original single-thread implementation with the optimized
implementations.

5.  The locations of the output disparity maps are given in the console output.  More detailed info including input
stereo set and parameters, detailed timings along with overall speedup data, and output disparity map evaluation as
compared to ground truth for each run are written to a
outputResultsDefaultParallelParams_MULT_DATA_TYPES_{acceleration_type}.csv file; this file is in the same folder as
the driverCPUBp/driverCudaBp executable.

6.  To adjust the program to run on different inputs or with different parameters, set the desired
parameters in BpConstsAndParams/bpStereoParameters.h, run "make clean" and "make" to compile the program with the
adjusted parameters, and then call the executable to run the program with the adjusted parameters.


RUNTIME RESULTS USING CURRENT CODE:

Relative speedup across various processors using float type w/ prior run using AMD Rome (48 cores) used as baseline:
-Column marked as "Total runtime including data transfer time (15 timings)" in 
outputResultsDefaultParallelParams_MULT_DATA_TYPES_{acceleration_type}.csv used for runtime comparison.
-Speedup given is average across a number of input stereo sets and configurations.
-CPU and CUDA runs are with thread count / thread block optimization enabled (via OPTIMIZE_PARALLEL_PARAMS in MainDriverFiles/driverCudaBp.cpp / MainDriverFiles/driverBpStereoCPU.cpp set to true)
NVIDIA H100: 2.41x
AMD Genoa-X (88 Cores*): 2.17x
NVIDIA A100: 1.80x
NVIDIA RTX 3090 Ti: 1.65x
Intel Sapphire Rapids (48 cores): 1.52x
AMD Milan-X (60 cores*): 1.35x
Amazon Graviton3 (64 core ARM server): 1.21x
NVIDIA V100: 1.14x
Amphere Altra (80 cores): 1.00x
Intel Ice Lake (32 cores): 0.975x
AMD Rome (48 cores): 0.97x
Amazon Graviton2 (64 core ARM server): 0.925x
NVIDIA P100: 0.785x
Intel Cascade Lake (24 cores): 0.63x
Spreadsheet with detailed results:
https://docs.google.com/spreadsheets/d/1pFMbbEGv1ulor1HP0lZNnd1IL8xETfr3tHRk_S9VzzE/edit?usp=sharing

*Run on system with 2 socketed CPUs with total of 2x listed core count across CPUs and with SMT disabled...benchmarked
runs are with max number of threads limited to core count on single CPU w/ threads pinned to socket so should be using
single CPU in the run.
Commands to pin OMP threads to socket:
export OMP_PLACES="sockets"
export OMP_PROC_BIND=true


ADDITIONAL NOTE:

There is a known bug where the output disparity map from the CUDA-accelerated code is not at all similar to the
single-thread output disparity map in the test with conesFullSizeCropped at half precision...likely reason for
this is that half-precision value(s) in processing in the CUDA kernels become either infinity or NaN.  If using 
a CUDA device with compute capability 8.0 or later, can switch CUDA processing at half precision from the "half"
datatype to the bfloat16 datatype to fix this bug (at least in the conesFullSizeCropped test) by removing the
comment in the line "BFLOAT_DATA_TYPE_SETTING = #-DUSE_BFLOAT16_FOR_HALF_PRECISION" in
LinuxMakeAndRunBPCUDA/Makefile (line 28).


WINDOWS INSTRUCTIONS (OUTDATED...HASN'T BEEN MAINTAINED FOR AWHILE):

1.  Open CreateBeliefPropDLLs.sln Visual Studio Project in WindowsVSCreateDLLsWithRunBPWithDLLs/CreateBeliefPropDLLs folder.  

2.  Select to compile then run the application.  The solution will first compile the single-thread CPU, optimized CPU, 
and CUDA implementations into DLLs, then the main program in the solution will load the DLLs and run the program.  The
program output shows the optimized CPU and CUDA implementation results compared to the single-thread CPU implementation results.

Parameters can be adjusted in the BpConstsAndParams/bpStereoParameters.h file and will need to re-compile to see results with adjusted parameters.
